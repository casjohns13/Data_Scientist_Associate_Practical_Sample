{"cells":[{"source":"# Practical Exam: Supermarket Loyalty\n\nInternational Essentials is an international supermarket chain.\n\nShoppers at their supermarkets can sign up for a loyalty program that provides rewards each year to customers based on their spending. The more you spend the bigger the rewards. \n\nThe supermarket would like to be able to predict the likely amount customers in the program will spend, so they can estimate the cost of the rewards. \n\nThis will help them to predict the likely profit at the end of the year.\n\n## Data\n\nThe dataset contains records of customers for their last full year of the loyalty program.\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n|customer_id | Unique identifier for the customer. </br>Missing values are not possible due to the database structure. |\n|spend | Continuous. </br>The total spend of the customer in their last full year. This can be any positive value to two decimal places. </br>Missing values should be replaced with 0. |\n|first_month | Continuous. </br>The amount spent by the customer in their first month of the year. This can be any positive value, rounded to two decimal places. </br>Missing values should be replaced with 0. |\n| items_in_first_month | Discrete. </br>The number of items purchased in the first month. Any integer value greater than or equal to zero. </br>Missing values should be replaced by 0. |  \n| region | Nominal. </br>The geographic region that the customer is based in. One of four values Americas, Asia/Pacific, Europe, Middle East/Africa. </br>Missing values should be replaced with \"Unknown\". |\n| loyalty_years | Oridinal. </br>The number of years the customer has been a part of the loyalty program. One of five ordered categories, '0-1', '1-3', '3-5', '5-10', '10+'. </br>Missing values should be replaced with '0-1'.|\n| joining_month | Nominal. </br>The month the customer joined the loyalty program. One of 12 values \"Jan\", \"Feb\", \"Mar\", \"Apr\", etc. </br>Missing values should be replaced with \"Unknown\".|\n| promotion | Nominal. </br>Did the customer join the loyalty program as part of a promotion? Either 'Yes' or 'No'. </br>Missing values should be replaced with 'No'.|\n","metadata":{},"id":"0a8ca74a-b235-4034-9c1c-3159336a39d5","cell_type":"markdown"},{"source":"# Task 1\n\nBefore you fit any models, you will need to make sure the data is clean. \n\nThe table below shows what the data should look like. \n\nCreate a cleaned version of the dataframe. \n\n - You should start with the data in the file \"loyalty.csv\". \n\n - Your output should be a dataframe named `clean_data`. \n\n - All column names and values should match the table below.\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n|customer_id | Unique identifier for the customer. </br>Missing values are not possible due to the database structure. |\n|spend | Continuous. </br>The total spend of the customer in their last full year. This can be any positive value to two decimal places. </br>Missing values should be replaced with 0. |\n|first_month | Continuous. </br>The amount spent by the customer in their first month of the year. This can be any positive value, rounded to two decimal places. </br>Missing values should be replaced with 0. |\n| items_in_first_month | Discrete. </br>The number of items purchased in the first month. Any integer value greater than or equal to zero. </br>Missing values should be replaced by 0. |  \n| region | Nominal. </br>The geographic region that the customer is based in. One of four values Americas, Asia/Pacific, Europe, Middle East/Africa. </br>Missing values should be replaced with \"Unknown\". |\n| loyalty_years | Oridinal. </br>The number of years the customer has been a part of the loyalty program. One of five ordered categories, '0-1', '1-3', '3-5', '5-10', '10+'. </br>Missing values should be replaced with '0-1'.|\n| joining_month | Nominal. </br>The month the customer joined the loyalty program. One of 12 values \"Jan\", \"Feb\", \"Mar\", \"Apr\", etc. </br>Missing values should be replaced with \"Unknown\".|\n| promotion | Nominal. </br>Did the customer join the loyalty program as part of a promotion? Either 'Yes' or 'No'. </br>Missing values should be replaced with 'No'.|","metadata":{},"id":"790f8bb8-76fb-44fd-8078-c62909a91b2b","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 1\nimport pandas as pd\nimport numpy as np\nloyalty_df = pd.read_csv('loyalty.csv')\nprint(loyalty_df.info())\n\n#Checking customer_id column. Nothing needed to be done\nprint('Checking customer_id column:')\nprint(loyalty_df['customer_id'].nunique())\n\n#Checking spend column, ensuring all values are above 0 and rounding to two decimal points\nprint('Checking spend column:')\nprint (np.sum(loyalty_df['spend'] <= 0))\nloyalty_df['spend'] = round(loyalty_df['spend'], 2)\n\n#Checking first_month column, converting to a float, rounding to two decimal places and ensuring all values are 0 or above\nprint('Checking first_month column:')\nloyalty_df['first_month'] = pd.to_numeric(loyalty_df['first_month'], errors='coerce')\nloyalty_df['first_month'] = round(loyalty_df['first_month'], 2)\nprint(loyalty_df['first_month'].isna().sum(), np.sum(loyalty_df['first_month'] < 0))\nloyalty_df.loc[loyalty_df['first_month'].isna(), 'first_month'] = 0\nprint(loyalty_df['first_month'].isna().sum())\n\n#Checking items_in_first_month column, ensuring values are above 0. Nothing needed to be done.\nprint('Checking items_in_first_month column:')\nprint(np.sum(loyalty_df['items_in_first_month'] < 0))\n\n#Checking region column and converting values to 'category'\nprint('Checking region column:')\nprint(loyalty_df['region'].unique())\nloyalty_df['region'] = loyalty_df['region'].astype('category')\nprint(loyalty_df['region'].dtype)\n\n#Checking loyalty_years column and coverterting to ordered categories\nprint('Checking loyalty_years column:')\nprint(loyalty_df['loyalty_years'].unique())\nloyalty_df['loyalty_years'] = loyalty_df['loyalty_years'].astype('category')\nloyalty_df['loyalty_years'].cat.reorder_categories(new_categories = ['0-1', '1-3', '3-5', '5-10', '10+'], ordered=True, inplace=True)\nprint(loyalty_df['loyalty_years'].cat.categories)\n\n#Checking joining_month column, replacing NaN values with 'unknown', and converting to category\nprint('Checking joining_month column:')\nprint(loyalty_df['joining_month'].unique())\nloyalty_df['joining_month'].fillna('Unknown', inplace=True)\nprint(loyalty_df['joining_month'].unique(), loyalty_df['joining_month'].isna().sum())\nloyalty_df['joining_month'] = loyalty_df['joining_month'].astype('category')\n\n#Checking promotion column, minimizing down to one 'Yes' and one 'No' value, and converting to category\nprint('Checking promotion column:')\nprint(loyalty_df['promotion'].unique())\nloyalty_df['promotion'] = loyalty_df['promotion'].str.title()\nprint(loyalty_df['promotion'].unique())\nloyalty_df['promotion'] = loyalty_df['promotion'].astype('category')\n\nclean_data = loyalty_df\nprint(clean_data.info())","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1756675784609,"lastExecutedByKernel":"d09a6094-8c50-4719-a6db-b95517de74a7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 1\nimport pandas as pd\nimport numpy as np\nloyalty_df = pd.read_csv('loyalty.csv')\nprint(loyalty_df.info())\n\n#Checking customer_id column. Nothing needed to be done\nprint('Checking customer_id column:')\nprint(loyalty_df['customer_id'].nunique())\n\n#Checking spend column, ensuring all values are above 0 and rounding to two decimal points\nprint('Checking spend column:')\nprint (np.sum(loyalty_df['spend'] <= 0))\nloyalty_df['spend'] = round(loyalty_df['spend'], 2)\n\n#Checking first_month column, converting to a float, rounding to two decimal places and ensuring all values are 0 or above\nprint('Checking first_month column:')\nloyalty_df['first_month'] = pd.to_numeric(loyalty_df['first_month'], errors='coerce')\nloyalty_df['first_month'] = round(loyalty_df['first_month'], 2)\nprint(loyalty_df['first_month'].isna().sum(), np.sum(loyalty_df['first_month'] < 0))\nloyalty_df.loc[loyalty_df['first_month'].isna(), 'first_month'] = 0\nprint(loyalty_df['first_month'].isna().sum())\n\n#Checking items_in_first_month column, ensuring values are above 0. Nothing needed to be done.\nprint('Checking items_in_first_month column:')\nprint(np.sum(loyalty_df['items_in_first_month'] < 0))\n\n#Checking region column and converting values to 'category'\nprint('Checking region column:')\nprint(loyalty_df['region'].unique())\nloyalty_df['region'] = loyalty_df['region'].astype('category')\nprint(loyalty_df['region'].dtype)\n\n#Checking loyalty_years column and coverterting to ordered categories\nprint('Checking loyalty_years column:')\nprint(loyalty_df['loyalty_years'].unique())\nloyalty_df['loyalty_years'] = loyalty_df['loyalty_years'].astype('category')\nloyalty_df['loyalty_years'].cat.reorder_categories(new_categories = ['0-1', '1-3', '3-5', '5-10', '10+'], ordered=True, inplace=True)\nprint(loyalty_df['loyalty_years'].cat.categories)\n\n#Checking joining_month column, replacing NaN values with 'unknown', and converting to category\nprint('Checking joining_month column:')\nprint(loyalty_df['joining_month'].unique())\nloyalty_df['joining_month'].fillna('Unknown', inplace=True)\nprint(loyalty_df['joining_month'].unique(), loyalty_df['joining_month'].isna().sum())\nloyalty_df['joining_month'] = loyalty_df['joining_month'].astype('category')\n\n#Checking promotion column, minimizing down to one 'Yes' and one 'No' value, and converting to category\nprint('Checking promotion column:')\nprint(loyalty_df['promotion'].unique())\nloyalty_df['promotion'] = loyalty_df['promotion'].str.title()\nprint(loyalty_df['promotion'].unique())\nloyalty_df['promotion'] = loyalty_df['promotion'].astype('category')\n\nclean_data = loyalty_df\nprint(clean_data.info())","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"523dd03c-8591-4cc6-b750-d71da287745f","cell_type":"code","execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1246 entries, 0 to 1245\nData columns (total 8 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   customer_id           1246 non-null   int64  \n 1   spend                 1246 non-null   float64\n 2   first_month           1246 non-null   object \n 3   items_in_first_month  1246 non-null   int64  \n 4   region                1246 non-null   object \n 5   loyalty_years         1246 non-null   object \n 6   joining_month         1121 non-null   object \n 7   promotion             1246 non-null   object \ndtypes: float64(1), int64(2), object(5)\nmemory usage: 78.0+ KB\nNone\nChecking customer_id column:\n1246\nChecking spend column:\n0\nChecking first_month column:\n125 0\n0\nChecking items_in_first_month column:\n0\nChecking region column:\n['Asia/Pacific' 'Middle East/Africa' 'Europe' 'Americas']\ncategory\nChecking loyalty_years column:\n['5-10' '0-1' '10+' '3-5' '1-3']\nIndex(['0-1', '1-3', '3-5', '5-10', '10+'], dtype='object')\nChecking joining_month column:\n['Nov' 'Feb' 'Dec' 'Apr' 'May' nan 'Jul' 'Oct' 'Jan' 'Sep' 'Mar' 'Jun'\n 'Aug']\n['Nov' 'Feb' 'Dec' 'Apr' 'May' 'Unknown' 'Jul' 'Oct' 'Jan' 'Sep' 'Mar'\n 'Jun' 'Aug'] 0\nChecking promotion column:\n['No' 'Yes' 'NO' 'YES']\n['No' 'Yes']\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1246 entries, 0 to 1245\nData columns (total 8 columns):\n #   Column                Non-Null Count  Dtype   \n---  ------                --------------  -----   \n 0   customer_id           1246 non-null   int64   \n 1   spend                 1246 non-null   float64 \n 2   first_month           1246 non-null   float64 \n 3   items_in_first_month  1246 non-null   int64   \n 4   region                1246 non-null   category\n 5   loyalty_years         1246 non-null   category\n 6   joining_month         1246 non-null   category\n 7   promotion             1246 non-null   category\ndtypes: category(4), float64(2), int64(2)\nmemory usage: 45.1 KB\nNone\n"}]},{"source":"# Task 2 \n\nThe team at International Essentials have told you that they have always believed that the number of years in the loyalty scheme is the biggest driver of spend. \n\nProducing a table showing the difference in the average spend by number of years in the loyalty programme along with the variance to investigate this question for the team.\n\n - You should start with the data in the file 'loyalty.csv'.\n\n - Your output should be a data frame named `spend_by_years`. \n\n - It should include the three columns `loyalty_years`, `avg_spend`, `var_spend`. \n\n - Your answers should be rounded to 2 decimal places.   ","metadata":{},"id":"08b695b7-67db-48fb-8b14-e12bb5a9620e","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 2\nloyalty_df2 = pd.read_csv('loyalty.csv')\nspend_by_years = loyalty_df2.groupby('loyalty_years')['spend'].agg(['mean', 'var'])\nspend_by_years = spend_by_years.rename(columns = {'mean': 'avg_spend',\n                                                 'var': 'var_spend'})\nspend_by_years = spend_by_years.round(2)\nspend_by_years = spend_by_years.reset_index(drop=False)\nprint(spend_by_years)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1756675784656,"lastExecutedByKernel":"d09a6094-8c50-4719-a6db-b95517de74a7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 2\nloyalty_df2 = pd.read_csv('loyalty.csv')\nspend_by_years = loyalty_df2.groupby('loyalty_years')['spend'].agg(['mean', 'var'])\nspend_by_years = spend_by_years.rename(columns = {'mean': 'avg_spend',\n                                                 'var': 'var_spend'})\nspend_by_years = spend_by_years.round(2)\nspend_by_years = spend_by_years.reset_index(drop=False)\nprint(spend_by_years)","outputsMetadata":{"0":{"height":164,"type":"stream"},"1":{"height":616,"type":"stream"}}},"id":"cc590298-c483-4253-bef1-a352933cbd5e","cell_type":"code","execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":"  loyalty_years  avg_spend  var_spend\n0           0-1     110.56       9.30\n1           1-3     129.31       9.65\n2           10+     117.41      16.72\n3           3-5     124.55      11.09\n4          5-10     135.15      14.10\n"}]},{"source":"# Task 3\n\nFit a baseline model to predict the spend over the year for each customer.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “test.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `customer_id` and `spend`. The `spend` column must be your predicted values.","metadata":{},"id":"7113acde-8a74-487a-8983-f0c93003d945","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 3\n\n#Reading in the train and test sets\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\nprint(train['region'].unique(), train['loyalty_years'].unique(), train['joining_month'].unique(), train['promotion'].unique())\nprint(train['loyalty_years'].dtype)\n\n#Performing one-hot encoding on the categorical columns in the train and test sets\ntrain = pd.get_dummies(train, columns=['region','loyalty_years', 'joining_month', 'promotion'])\ntest = pd.get_dummies(test, columns = ['region', 'loyalty_years', 'joining_month', 'promotion'])\n\n#Creating X_train, y_train, and X_test\nX_train = train.drop(columns=['customer_id','spend'])\ny_train = train[['spend']]\nX_test = test.drop(columns = ['customer_id'])\n\n#Create a linear regression model\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\n#Create base_result DataFrame\nbase_result = pd.concat([test, pd.DataFrame(y_pred, columns = ['spend'])], axis=1)\nbase_result = base_result[['customer_id', 'spend']]\n\nprint(base_result)\n","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1756675784709,"lastExecutedByKernel":"d09a6094-8c50-4719-a6db-b95517de74a7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 3\n\n#Reading in the train and test sets\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\nprint(train['region'].unique(), train['loyalty_years'].unique(), train['joining_month'].unique(), train['promotion'].unique())\nprint(train['loyalty_years'].dtype)\n\n#Performing one-hot encoding on the categorical columns in the train and test sets\ntrain = pd.get_dummies(train, columns=['region','loyalty_years', 'joining_month', 'promotion'])\ntest = pd.get_dummies(test, columns = ['region', 'loyalty_years', 'joining_month', 'promotion'])\n\n#Creating X_train, y_train, and X_test\nX_train = train.drop(columns=['customer_id','spend'])\ny_train = train[['spend']]\nX_test = test.drop(columns = ['customer_id'])\n\n#Create a linear regression model\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\n#Create base_result DataFrame\nbase_result = pd.concat([test, pd.DataFrame(y_pred, columns = ['spend'])], axis=1)\nbase_result = base_result[['customer_id', 'spend']]\n\nprint(base_result)\n","outputsMetadata":{"0":{"height":80,"type":"stream"},"1":{"height":500,"type":"dataFrame","tableState":{}}}},"id":"79a77f11-b09b-4d70-893b-535dfde919b2","cell_type":"code","execution_count":125,"outputs":[{"output_type":"stream","name":"stdout","text":"['Middle East/Africa' 'Europe' 'Asia/Pacific' 'Americas'] ['5-10' '10+' '1-3' '0-1' '3-5'] ['Feb' 'Jun' 'Oct' 'Sep' 'May' 'Nov' 'Mar' 'Jul' 'Jan' 'Aug' 'Apr' 'Dec'] ['Yes' 'No']\nobject\n     customer_id       spend\n0              5  140.699644\n1              7  148.730919\n2             16  140.810384\n3             17  150.649670\n4             19  153.628831\n..           ...         ...\n245         1216  134.869770\n246         1225  148.542583\n247         1231  136.969013\n248         1242  129.885730\n249         1243  148.518401\n\n[250 rows x 2 columns]\n"}]},{"source":"# Task 4\n\nFit a comparison model to predict the spend over the year for each customer.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “test.csv” to predict new values based on your model. You must return a dataframe named `compare_result`, that includes `customer_id` and `spend`. The `spend` column must be your predicted values.","metadata":{},"id":"44033abf-a603-479e-8663-9a96fefee5a2","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 4\n\n#Reading in the train and test datasets\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\n\n#Performing one-hot encoding on the categorical features of the train and test sets\ntrain = pd.get_dummies(train, columns=['region','loyalty_years', 'joining_month', 'promotion'])\ntest = pd.get_dummies(test, columns = ['region', 'loyalty_years', 'joining_month', 'promotion'])\n\n#Creating X_train, y_train, and X_test\nX_train = train.drop(columns=['customer_id','spend'])\ny_train = train[['spend']]\nX_test = test.drop(columns = ['customer_id'])\n\n#Creating a RandomForestRegressor model\nfrom sklearn.ensemble import RandomForestRegressor\nrfg = RandomForestRegressor(n_estimators = 400, min_samples_leaf = 0.1, random_state = 1)\nrfg.fit(X_train, y_train)\ny_pred_2 = rfg.predict(X_test)\n\n#Creating compare_result\ncompare_result = pd.concat([test, pd.DataFrame(y_pred_2, columns = ['spend'])], axis = 1)\ncompare_result = compare_result[['customer_id', 'spend']]\nprint(compare_result)","metadata":{"executionCancelledAt":null,"executionTime":562,"lastExecutedAt":1756675785271,"lastExecutedByKernel":"d09a6094-8c50-4719-a6db-b95517de74a7","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 4\n\n#Reading in the train and test datasets\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\n\n#Performing one-hot encoding on the categorical features of the train and test sets\ntrain = pd.get_dummies(train, columns=['region','loyalty_years', 'joining_month', 'promotion'])\ntest = pd.get_dummies(test, columns = ['region', 'loyalty_years', 'joining_month', 'promotion'])\n\n#Creating X_train, y_train, and X_test\nX_train = train.drop(columns=['customer_id','spend'])\ny_train = train[['spend']]\nX_test = test.drop(columns = ['customer_id'])\n\n#Creating a RandomForestRegressor model\nfrom sklearn.ensemble import RandomForestRegressor\nrfg = RandomForestRegressor(n_estimators = 400, min_samples_leaf = 0.1, random_state = 1)\nrfg.fit(X_train, y_train)\ny_pred_2 = rfg.predict(X_test)\n\n#Creating compare_result\ncompare_result = pd.concat([test, pd.DataFrame(y_pred_2, columns = ['spend'])], axis = 1)\ncompare_result = compare_result[['customer_id', 'spend']]\nprint(compare_result)","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"id":"731cfa01-2709-413a-ac19-611e73e37c75","cell_type":"code","execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":"     customer_id       spend\n0              5  136.662405\n1              7  146.688899\n2             16  135.832478\n3             17  147.407515\n4             19  147.407515\n..           ...         ...\n245         1216  136.873890\n246         1225  146.688899\n247         1231  135.784332\n248         1242  136.155274\n249         1243  146.688899\n\n[250 rows x 2 columns]\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}